{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from operator import itemgetter\n",
    "dataPath = \"./INTEGRATED-DATASET.csv\"\n",
    "\n",
    "\n",
    "\n",
    "dataSet = pd.read_csv(dataPath)\n",
    "dataSet.columns = [\"Name\", \"Borough\", \"Type\", \"InspectionSeason\", \"Reason\", \"Critical\", \"Score\", \"Grade\", \"GradeSeason\"]\n",
    "dataSet\n",
    "min_supp = 0*len(dataSet)\n",
    "min_conf = 0.1*len(dataSet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Lk(one_item_set):\n",
    "    Union_Lk = []\n",
    "    Union_Lk.append(one_item_set)\n",
    "    k=1\n",
    "    while len(Union_Lk[-1])!=0 and k<=4:\n",
    "        Ck = apriori_gen(Union_Lk[-1], k)\n",
    "        for idx, c in enumerate(Ck):\n",
    "            cols = []\n",
    "            vals = []\n",
    "            for item in c:\n",
    "                cols.append(item[0])\n",
    "                vals.append(item[1])\n",
    "            gb = dataSet.groupby(cols)\n",
    "            try:\n",
    "                if len(gb.get_group(tuple(vals))) < min_supp:\n",
    "                    del Ck[idx]            \n",
    "            except KeyError:\n",
    "                del Ck[idx]            \n",
    "\n",
    "        Union_Lk.append(Ck)\n",
    "        k=k+1\n",
    "    return Union_Lk\n",
    "\n",
    "        \n",
    "def apriori_gen(Lk_minus1, k):\n",
    "    Ck = []\n",
    "    print(len(Lk_minus1))\n",
    "    for i in xrange(0, len(Lk_minus1)):\n",
    "        for j in xrange(i+1, len(Lk_minus1)):\n",
    "            if check_match(Lk_minus1[i], Lk_minus1[j]):\n",
    "                \n",
    "                new_item_set = Lk_minus1[i][:]\n",
    "                new_item_set.append(Lk_minus1[j][-1])\n",
    "                if k==1 or check_subset(Lk_minus1, new_item_set):\n",
    "                    Ck.append(new_item_set)\n",
    "#     sort(Ck) not sure if we need to sort it                \n",
    "    return Ck                \n",
    "def check_subset(Lk_minus1, new_item_set):\n",
    "    for i in xrange(len(new_item_set)):\n",
    "        subset = copy.deepcopy(new_item_set)\n",
    "        del subset[i]\n",
    "        if subset not in Lk_minus1:\n",
    "            \n",
    "            return False\n",
    "    return True\n",
    "            \n",
    "            \n",
    "        \n",
    "def check_match(set1, set2):\n",
    "    for i in xrange(len(set1)-1):\n",
    "        \n",
    "        if set1[i]!=set2[i]: return False\n",
    "    if set1[-1][0]==set2[-1][0]: \n",
    "        return False\n",
    "    if set1[-1][0]!=set2[-1][0] and set1[-1][1]!=set2[-1][1]: return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Borough', 'BRONX')], [('Borough', 'BROOKLYN')], [('Borough', 'MANHATTAN')], [('Borough', 'QUEENS')], [('Borough', 'STATEN ISLAND')], [('Grade', 'A')], [('Grade', 'B')], [('Grade', 'C')], [('Grade', 'P')], [('Grade', 'Z')], [('GradeSeason', 'Spring-GRADE DATE')], [('GradeSeason', 'Summer-GRADE DATE')], [('GradeSeason', 'Winter-GRADE DATE')], [('Type', 'African')], [('Type', 'Asian')], [('Type', 'European')], [('Type', 'NorthAmerican')], [('Type', 'Other')], [('Type', 'SouthAmerican')]]\n"
     ]
    }
   ],
   "source": [
    "def get_L1(dataSet, one_item):\n",
    "    for item in one_item:\n",
    "        cntType = dataSet.groupby(item).count()\n",
    "        one_item[item] = [x for x in one_item[item] if cntType.at[x, 'Name'] >= min_supp]\n",
    "\n",
    "def init_one_item_set(one_item, one_item_set):\n",
    "    for key in one_item:\n",
    "        for val in one_item[key]:\n",
    "            new_item_set = []\n",
    "            new_item_set.append((key, val))\n",
    "            one_item_set.append(new_item_set)\n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "boroughs = dataSet[\"Borough\"].unique()\n",
    "grades = dataSet[\"Grade\"].unique()\n",
    "types = dataSet[\"Type\"].unique()\n",
    "gradeSeason = dataSet[\"GradeSeason\"].unique()\n",
    "\n",
    "gradeSeason = np.delete(gradeSeason, gradeSeason.shape[0]-1).tolist()\n",
    "types = np.delete(types, types.shape[0]-1).tolist()\n",
    "grades = np.delete(grades, grades.shape[0]-1).tolist()\n",
    "boroughs = np.delete(boroughs, boroughs.shape[0]-1).tolist()\n",
    "\n",
    "one_item={}\n",
    "one_item[\"Type\"] = types\n",
    "one_item[\"Borough\"] = boroughs\n",
    "one_item[\"Grade\"] = grades\n",
    "one_item[\"GradeSeason\"] = gradeSeason\n",
    "get_L1(dataSet, one_item)\n",
    "\n",
    "one_item_set = []\n",
    "init_one_item_set(one_item, one_item_set)\n",
    "\n",
    "one_item_set = sorted(one_item_set, key=lambda x: (x[0],x[0][1]))\n",
    "print(one_item_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "133\n",
      "388\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "Union_Lk = get_Lk(one_item_set)\n",
    "# Union_Lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.DataFrameGroupBy object at 0x10aa13990>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri = dataSet.groupby(['Borough', 'Grade', 'Type'])\n",
    "tri\n",
    "# print tri.get_group(('BRONX', 'B', 'SouthAmerican'))\n",
    "# tri[[\"Type\", \"Borough\"]].get_group((\"Type\", \"Borough\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-635aeb090995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion_Lk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataSet' is not defined"
     ]
    }
   ],
   "source": [
    "def pick_up_cal(df, result):\n",
    "    temp = df\n",
    "    for index in range(len(result)):\n",
    "        temp = temp[temp[result[index][0]] == result[index][1]]\n",
    "    return temp.shape[0]\n",
    "\n",
    "def pick_up_num(df, num, selected, remains, index):\n",
    "    result = []\n",
    "    if num > len(remains) - index:\n",
    "        return []\n",
    "    if num == 0:\n",
    "        A = pick_up_cal(df, selected+remains)\n",
    "        B = pick_up_cal(df, selected)\n",
    "        return [json.dumps({\"RHS\": selected+remains, \"LHS\":selected, \"Confidence\": A*1.0/B})]\n",
    "    result += pick_up_num(df, num, selected, remains, index+1)\n",
    "    result += pick_up_num(df, num-1, selected + [remains[index]], remains[:index] + remains[index+1:], index)\n",
    "    return result\n",
    "    \n",
    "# sample = [('Borough', 'BRONX'), ('Grade', 'A'), ('Type', 'African')]\n",
    "# pick_up_cal(dataSet, sample)\n",
    "\n",
    "# print pick_up_num(dataSet, 2, [], sample, 0)\n",
    "\n",
    "def generate_fit(df, result, threshold):\n",
    "    submit = []\n",
    "    for level, value in enumerate(result):\n",
    "        # under 1st Level\n",
    "        if level == 0: continue\n",
    "        for index, item in enumerate(value):\n",
    "            # e.g item = [('Borough', 'BRONX'), ('Grades', 'A')]\n",
    "            num = level + 1\n",
    "            for i in range(1, num):\n",
    "                submit += pick_up_num(df, i, [], item, 0)\n",
    "    return submit\n",
    "\n",
    "final = generate_fit(dataSet, Union_Lk, 0.5)\n",
    "\n",
    "confidence = 0.6\n",
    "\n",
    "for item in final:\n",
    "    temp = json.loads(item)\n",
    "    if temp[\"Confidence\"] > confidence: print temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
