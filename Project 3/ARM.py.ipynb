{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "dataPath = \"./INTEGRATED-DATASET.csv\"\n",
    "\n",
    "\n",
    "\n",
    "dataSet = pd.read_csv(dataPath)\n",
    "dataSet.columns = [\"Name\", \"Borough\", \"Type\", \"InspectionSeason\", \"Reason\", \"Critical\", \"Score\", \"Grade\", \"GradeSeason\"]\n",
    "dataSet\n",
    "min_supp = 0.4*len(dataSet)\n",
    "min_conf = 0.1*len(dataSet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_L1(dataSet, one_item):\n",
    "    for item in one_item:\n",
    "        cntType = dataSet.groupby(item).count()\n",
    "        one_item[item] = [x for x in one_item[item] if cntType.at[x, 'Name'] >= min_supp]\n",
    "\n",
    "def get_Lk(one_item):\n",
    "    Union_Lk = []\n",
    "    Uninion_Lk.append(one_item)\n",
    "    while len(Union_Lk[-1])!=0:\n",
    "        Ck = apriori_gen(Uniion_Lk[-1])\n",
    "        Ck.sort()\n",
    "        Union_Lk.append([])\n",
    "\n",
    "        \n",
    "def apriori_gen(Lk_minus1):\n",
    "    Ck = []\n",
    "    for i in xrange(0, len(Lk_minus1)):\n",
    "        for j in xrange(i+1, len(Lk_minus1)):\n",
    "            if check_match(Lk_minus1[i], Lk_minus1[j]):\n",
    "            \n",
    "            \n",
    "        \n",
    "def check_match(set1, set2):\n",
    "    for i in xrange(len(set1)-1):\n",
    "        if(set1[i]!=set2[j]) return False\n",
    "    if set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Borough', 'BRONX'), ('Borough', 'MANHATTAN'), ('Borough', 'BROOKLYN'), ('Borough', 'QUEENS'), ('Borough', 'STATEN ISLAND'), ('GradeSeason', 'Winter-GRADE DATE'), ('GradeSeason', 'Summer-GRADE DATE'), ('GradeSeason', 'Spring-GRADE DATE'), ('Grades', 'A'), ('Grades', 'B'), ('Grades', 'C'), ('Grades', 'P'), ('Grades', 'Z'), ('Type', 'NorthAmerican'), ('Type', 'European'), ('Type', 'Asian'), ('Type', 'Other'), ('Type', 'African'), ('Type', 'SouthAmerican')]\n"
     ]
    }
   ],
   "source": [
    "def init_one_item(one_item, key, values):\n",
    "    for val in values:\n",
    "        one_item.append((key, val))\n",
    "\n",
    "boroughs = dataSet[\"Borough\"].unique()\n",
    "grades = dataSet[\"Grade\"].unique()\n",
    "types = dataSet[\"Type\"].unique()\n",
    "gradeSeason = dataSet[\"GradeSeason\"].unique()\n",
    "\n",
    "gradeSeason = np.delete(gradeSeason, gradeSeason.shape[0]-1).tolist()\n",
    "types = np.delete(types, types.shape[0]-1).tolist()\n",
    "grades = np.delete(grades, grades.shape[0]-1).tolist()\n",
    "boroughs = np.delete(boroughs, boroughs.shape[0]-1).tolist()\n",
    "\n",
    "one_item=[]\n",
    "init_one_item(one_item, \"Type\", types)\n",
    "init_one_item(one_item, \"Borough\", boroughs)\n",
    "init_one_item(one_item, \"Grades\", grades)\n",
    "init_one_item(one_item, \"GradeSeason\", gradeSeason)\n",
    "\n",
    "one_item = sorted(one_item, key=itemgetter(0))\n",
    "print(one_item)\n",
    "\n",
    "get_L1(dataSet, one_item)\n",
    "# print (one_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
